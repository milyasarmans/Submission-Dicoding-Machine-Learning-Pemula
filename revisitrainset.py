# -*- coding: utf-8 -*-
"""revisiTrainSet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cU4W9vateBax_7XLQDYaFaSE_ROvXjLt

**PROFIL**</br>
Nama : M Ilyas Arman S </br>
Username : milyasarmans </br>
Email : milyasarmans13@gmail.com
"""

#memastikan bahwa versi TensorFlow > 2
import tensorflow as tf
print(tf.__version__)

#dataset RockPaperScissors
!wget --no-check-certificate \
https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

#ekstraksi file RockPaperScissors
import zipfile,os
local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('ilyas')
zip_ref.close()

#argumen validation_split
!pip install split_folders

import splitfolders
splitfolders.ratio('ilyas/rockpaperscissors/rps-cv-images', 'ilyas/rockpaperscissors/data', seed=2, ratio=(.6, .4))

#setiap direktori menyimpan gambar sesuai dengan nama sub
os.listdir('ilyas/rockpaperscissors/data/train')

os.listdir('ilyas/rockpaperscissors/data/val')

#membuat subdirektori
base_dir = 'ilyas/rockpaperscissors/data'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

# membuat direktori rock pada direktori train
train_rock_dir = os.path.join(train_dir, 'train')
 
# membuat direktori paper pada direktori train
train_paper_dir = os.path.join(train_dir, 'paper')
 
# membuat direktori scissors pada direktori train
train_scissors_dir = os.path.join(train_dir, 'scissors')
 
# membuat direktori rock pada direktori validation
validation_crock_dir = os.path.join(validation_dir, 'rock')
 
# membuat direktori paper pada direktori validation
validation_paper_dir = os.path.join(validation_dir, 'paper')
 
# membuat direktori scissors pada direktori validation
validation_scissors_dir = os.path.join(validation_dir, 'scissors')

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
  rescale=1./255,
  zoom_range=0.2, 
  horizontal_flip=True, 
  shear_range=0.2)

test_datagen = ImageDataGenerator(
  rescale=1./255, 
  zoom_range=0.2,
  horizontal_flip=True, 
  shear_range=0.2)

train_generator = train_datagen.flow_from_directory(
  train_dir,  # direktori data 
  target_size=(224, 224), # mengubah resolusi seluruh gambar menjadi 224x224 piksel
  batch_size=32, 
  color_mode='rgb', 
  class_mode='categorical', #mode 3 kelas
  shuffle = True, 
  seed=42)

validation_generator = test_datagen.flow_from_directory(
  validation_dir, # direktori data 
  target_size=(224, 224), # mengubah resolusi seluruh gambar menjadi 224x224 piksel
  batch_size=32,
  color_mode='rgb',
  class_mode='categorical',
  shuffle = True,
  seed=42)

sample_train_images, _ = next(train_generator)
sample_val_images, _ = next(validation_generator)

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

import matplotlib.pyplot as plt

plotImages(sample_train_images[:5])
plotImages(sample_val_images[:5])

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

# compile model dengan 'adam' optimizer loss function 'binary_crossentropy' 
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

historrry = model.fit(
    train_generator, 
    steps_per_epoch=25,  # berapa batch yang akan dieksekusi pada setiap epoch
    epochs=20, # tambahkan eposchs jika akurasi model belum optimal
    validation_data=validation_generator, # menampilkan akurasi pengujian data validasi
    validation_steps=5, # berapa batch yang akan dieksekusi pada setiap epoch
    verbose=1)

acc = historrry.history['accuracy']
val_acc = historrry.history['val_accuracy']

loss = historrry.history['loss']
val_loss = historrry.history['val_loss']

plt.plot(val_acc, color='yellow')
plt.plot(acc, color='green')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(loss, color='green')
plt.plot(val_loss, color='yellow')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(224,224))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  if classes[0,0]!=0:
    print('PAPER')
  elif classes[0,1]!=0:
    print('ROCK')
  else:
    print('SCISSORS')